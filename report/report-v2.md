# 社交网络挖掘项目报告：谣言检测

## 一、 选题介绍

在当今社交媒体高度发达的时代，信息的传播速度呈指数级增长。然而，这也为虚假信息和谣言的扩散提供了温床。谣言的广泛传播不仅会扰乱网络秩序，还可能引发社会恐慌，造成严重的现实后果。因此，如何利用计算机技术自动、高效地检测社交网络中的谣言，成为了一个极具挑战且意义重大的课题。

本小组选择“谣言监测”（Rumor Detection）作为本次项目的课题。我们的核心任务是构建一个二分类模型，根据已知的社交媒体帖子和相关的传播行为（如转发、评论等），将这个信息划分为“谣言”（Rumor）或者“非谣言”（Non-Rumor）。为了直观识别谣言和非谣言在传播中的特征和区别，我们首先进行探索性数据分析（EDA）来可视化数据集的部分特征，可视化结果也用于指导后续特征工程建模。

方法上，我们根据处理谣言检测问题的常见范式，分别探索了传统特征工程和基于图拓扑结构的建模，也尝试引入大语言模型（LLM）进行无需训练的推理。结果上，我们训练的图神经网络（GCN）模型性能表现优异，在测试集上达到 0.9425 的准确率。此外，我们从 LLM 的推理输出中发现其具备精准捕捉语义细节，给出可靠判据的能力。

本篇报告的后续内容如下组织：第二部分介绍了我们使用的数据集，并展示和分析 EDA 的结果；第三部分从原理上解释了我们使用的三个维度的五个模型；第四部分展示了我们在数据集上做的实验和各个模型性能对比，并结合可视化结果对数据的特征做了解释；第五部分总结了我们的项目并展望可以开展的进一步工作。

## 二、 数据集介绍

本次实验中，我们使用了 **CED (Chinese Rumor Dataset)** 数据集。该数据集包含从微博平台爬取的1538条谣言数据和1849条非谣言数据，为我们的谣言监测任务提供了丰富的特征。数据集中涉及的谣言和非谣言帖子都经过微博社区管理中心认证，具有较高的可信度。

CED数据集包含了鲜明的层次结构特征。对每一个样本，它包含了作为根节点的原始信息帖子的特征和传播树中各个子节点的转发行为。对于根节点，数据集包含了信息文本、发布时间和发布用户的特征（包括粉丝数、关注数、是否认证等）。对于转发子节点，数据集包含了转发文本、转发时间和转发的原帖，构成了完整的传播树结构。

数据集的具体大小如下表所示。需要说明的是，虽然谣言和非谣言都存在很小的转发树，但这种极端的数据占比并不多，经过检查，转发数大小小于20个节点的数据仅有7条，说明数据集整体提供了足够大的传播结构特征。

|  数据集   | 数据量 | 转发量 | 平均转发树大小 | 最小转发树大小 | 最大转发树大小 |
| :-------: | :----: | :----: | :------------: | :------------: | :------------: |
|   Rumor   |  1538  | 483617 |      314       |       3        |      954       |
| Non-Rumor |  1849  | 791563 |      428       |       5        |      964       |

### 2.1 数据可视化与探索性分析

我们首先展示部分信息传播图的可视化。为了保证可视化结果的代表性，我们对谣言和非谣言数据集分别选取了三个随机的序号，分别为谣言数据集 [52, 229, 1310], 非谣言数据集 [502, 564, 1519]（报告中序数从1开始计数）。它们的可视化结果完整展示如下：

<table>
  <tr>
    <td align="center">
      <img src="C:\Git\github_projects\SocialNetworkMining-RumorDetection\results\Rumor_Propagation_1.png" style="zoom:48%;"/>
    </td>
    <td align="center">
      <img src="C:\Git\github_projects\SocialNetworkMining-RumorDetection\results\NonRumor_Propagation_1.png" style="zoom:48%;"/>
    </td>
  </tr>
  <tr>
    <td align="center">
      <img src="C:\Git\github_projects\SocialNetworkMining-RumorDetection\results\Rumor_Propagation_2.png" style="zoom:48%;"/>
    </td>
    <td align="center">
      <img src="C:\Git\github_projects\SocialNetworkMining-RumorDetection\results\NonRumor_Propagation_2.png" style="zoom:48%;"/>
    </td>
  </tr>
  <tr>
    <td align="center">
      <img src="C:\Git\github_projects\SocialNetworkMining-RumorDetection\results\Rumor_Propagation_3.png" style="zoom:48%;"/>
    </td>
    <td align="center">
      <img src="C:\Git\github_projects\SocialNetworkMining-RumorDetection\results\NonRumor_Propagation_3.png" style="zoom:48%;"/>
    </td>
  </tr>
</table>
在传播图可视化结果中，我们通过根节点使用红色或者绿色区分谣言与非谣言。对于其他节点，我们区分了带有和不带有转发文本内容的节点。具体而言，带有转发文本的节点显示为蓝色，而转发文本为空的节点显示为灰色。由于直接展示完整传播图时，会出现节点过密导致可视化效果较差的现象，我们将没有孩子节点的一级转发节点每十个合并为一个。合并发生在蓝色节点或者灰色节点内部，所以得到的新节点继承了原节点的颜色，用于反映转发节点的文本特征。

由于我们抽取的传播图在总数据中占比依旧较小，我们从这六张传播图可视化结果中得到的解读不能完整代表所有数据，但可以提供一些简单的洞见，为我们后续的特征工程提供指导。我们可以发现，非谣言的传播树中灰色节点的占比相对较多，且在564号非谣言传播图中，出现了明显的灰色节点集中分布、集中转发的现象。而谣言传播图中，三张图都出现了明显的超长转发链，这是我们在非谣言传播图中没有发现的。我们猜测这可能反映了谣言传播中对真实性或者具体细节的深入讨论，或者对辟谣信息的印证和传播。

为了进一步探索谣言和非谣言数据的异同，我们做了全体数据维度的可视化内容。我们首先绘制了转发行为在一天二十四小时内的分布直方图。如下图所示，可以发现非谣言的转发在晚上23点至凌晨1点之间有一个明显的高峰，而其他时间段的分布大体相同。

<table>
  <tr>
    <td align="center">
      <img src="C:\Git\github_projects\SocialNetworkMining-RumorDetection\results\Rumor_Daily.png" style="zoom:48%;"/>
    </td>
    <td align="center">
      <img src="C:\Git\github_projects\SocialNetworkMining-RumorDetection\results\NonRumor_Daily.png" style="zoom:48%;"/>
    </td>
  </tr>
</table>

接着，我们可视化了每条转发信息相比于前一条转发间隔的时间。从下图的对比中，可以发现非谣言在0-5秒内的聚集转发占比更大，而谣言的转发会更加集中在15-120秒一条的间隔上。

<table>
  <tr>
    <td align="center">
      <img src="C:\Git\github_projects\SocialNetworkMining-RumorDetection\results\Rumor_Interval.png" style="zoom:48%;"/>
    </td>
    <td align="center">
      <img src="C:\Git\github_projects\SocialNetworkMining-RumorDetection\results\NonRumor_Interval.png" style="zoom:48%;"/>
    </td>
  </tr>
</table>
结合上述可视化结果，我们认为，整体上谣言的传播更加具有参与个体的真实性，而非谣言的传播存在深夜聚集转发和短时爆发性传播的现象，更可能存在水军的参与。

我们还对谣言和非谣言传播树的文本信息做了可视化，下面是两类信息的词云图。谣言的传播文本中，存在“吃惊”“怒”“汗”等等表示强烈情感的词语，以及“真的”“怎么”等加强语气的词语，透露出与情感的高相关性。而非谣言的传播文本中，存在“偷笑”“嘻嘻”“喜欢”等等相对比较轻松的词语，虽然依旧有“爱”“泪”等情感表达的词语，但整体情感相关词语较少，而且更加泛化。我们猜测，谣言的传播中，根节点通过夸大事实，引发大众情绪来博取关注，而非谣言的传播中，大家更加偏向聊轻松的、日常的话题，情感波动较小。

<table>
  <tr>
    <td align="center">
      <img src="C:\Git\github_projects\SocialNetworkMining-RumorDetection\results\Rumor_Wordcloud.png" style="zoom:48%;"/>
    </td>
    <td align="center">
      <img src="C:\Git\github_projects\SocialNetworkMining-RumorDetection\results\NonRumor_Wordcloud.png" style="zoom:48%;"/>
    </td>
  </tr>
</table>

## 三、 算法模型

本章节中，我们将分别介绍我们在传统机器学习、图神经网络和大语言模型推理三个维度下使用的处理方法。我们希望通过对比利用不同特征维度的模型效果，找到谣言监测任务下最适配的处理方法。

### 1. 传统机器学习建模

在传统机器学习中，我们测试了经典的 Random Forest (随机森林) 和 XGBoost (梯度提升树) 模型。基于数据集的内容和可视化的结果，我们设计了一系列手工特征，以捕捉样本在统计学、图拓扑结构等方面的信息，为分类和解释提供参考。需要说明的是，由于预计到文本特征对谣言的分类效果会有显著提升，我们为了测试其他维度特征的重要性，同时也是为了基于传统机器学习提供一个基线标准，没有在这里引入数据的文本特征。

首先，我们直接包含了数据集提供的部分统计学特征，主要包括：根节点图片数、评论数、转发数、获赞数、发布时间、根节点发布用户是否已认证、是否有个人简介、性别、消息数、粉丝数、好友数。这些特征主要从根节点的帖子和发布用户层面描述了样本。

其次，我们基于传播树的图结构引入了一些简单的特征，主要包括：传播图大小（转发数）、节点最大出度、平均出度、出度的标准差。这些节点从传播树的基本特征和传播行为可能涉及的特征方面描述了样本数据。

最后，我们基于可视化结果设计了如下特征：1）无文本转发的节点比例；2）传播树深度；3）23:00-24:00 发生的转发数、0:00-1:00 发生的转发数；4）间隔15秒内转发的节点数。

### 2. BERT (预训练语言模型)

BERT (Bidirectional Encoder Representations from Transformers) 是深度学习在 NLP 领域的里程碑。为了适配社交媒体谣言检测的多模态特性，我们并没有简单地直接套用原版 BERT，而是设计了一种基于语义增强的混合融合架构。

我们的 BERT 模型实现了一个独特的 **多模态后期融合架构**。社交媒体数据天然包含“非结构化文本”和“结构化数值”两类信息。我们的模型包含两个并行的特征提取流：1）文本流：利用 bert-base-chinese 作为骨干网络，通过 Transformer 编码器提取深层语义特征，取 [CLS] 向量作为整个事件的语义表示。2）数值流：将根节点的粉丝数、点赞数等数值特征标准化后，通过一个多层感知机 (MLP) 映射到高维空间。最终，我们将两路特征在分类层前进行拼接融合。这种设计使得模型既能理解“文本说了什么”（语义维度），又能考量“账号可信度如何”（社会学维度）。

### 3. LLM (Large Language Model - Gemini)

大语言模型（LLM）是当今人工智能中炙手可热的研究领域，具有广阔应用前景。我们在项目中调用 **Gemini 2.5 Flash Lite** API 进行无训练推理，探索通用 LLM 在任务上小样本推理的能力。选择这一模型主要从推理效率和经济效益出发，Flash Lite 版本在保持极高语义理解能力的同时，推理速度极快且成本低廉，这使得大规模、实时处理社交媒体数据成为可能。

我们将谣言检测任务转化为一个“基于证据的推理”问题。与传统模型不同，LLM 不需要繁琐的特征工程，而是直接阅读我们构建的 Prompt。Prompt 的设计采取结构化的方式，包含角色设定的系统指令、待判断内容和回答格式要求，用 LLM 友好的方式精准表述任务和要求。我们要求 LLM 不仅输出分类结果，还要输出推理的置信度和理由。这种 **“可解释性”** 是我们认为 LLM 相比于 BERT 等黑盒模型最大的应用价值所在。

我们给 LLM 提供了几个层面的信息：源博文、发布者关键数值特征和精心挑选的评论。我们采取了 **"Front-K + Back-M"** 策略（保留最早K条和最晚M条评论），这样的设计完美契合了谣言“始于煽动，止于智者”的传播规律。为了进一步提高推理的效率，我们还使用了 asyncio 和 Semaphore 进行异步并发推理，显著提升了大规模数据的检测效率。最后，由于 LLM 的回答存在小概率格式未严格遵循指令的可能，我们并构建了鲁棒的解析器，实现了层次化的解析。



### 4. GCN (图卷积神经网络)

图神经网络（GCN）是我们本次实验的重点，也是针对社交网络数据结构最自然的建模方式。因为谣言的传播本质上就是一个图结构的扩散过程。

**算法原理与实现细节**：
在我们的 GCN 实现中，我们将每个传播事件构建为一个图：每一个转发或评论是一个节点，转发关系构成边。
- **节点特征**：使用文本的词向量（TF-IDF或Word2Vec）作为初始特征。
- **图卷积层**：我们使用了两层图卷积网络。每一层卷积操作都会聚合邻居节点的信息，更新当前节点的特征表示。这意味着，经过两层卷积后，每个节点都融合了其二级邻居的信息。
- **池化与读出**：为了得到整个图（即整个事件）的表示，我们使用了全局池化（Global Pooling）策略，并创新性地将“根节点特征”（源帖子）与“全局池化特征”（整体传播情况）进行了拼接。这确保了模型既关注源头的内容，也关注传播过程的整体模式。

这种端到端的学习方式，让模型能够自动学习什么样的传播结构（例如单线传播 vs 广播式传播）更倾向于谣言。


## 四、实验结果与可视化

本章将从量化指标全面、稳健地评估不同模型的性能，再以一个具体的案例来展示和分析 LLM 的可解释性。

**实验设置与评估准则**：
1.  **稳健性评估**：我们采用了 **4 折交叉验证 (4-fold Cross Validation)** 策略。将训练集划分为 4 个子集，轮流作为验证集，以减少因数据划分偏差导致的性能波动，确保评估结果的真实可靠。
2.  **集成推理策略**：在最终的测试集预测中，对于需要训练的模型（BERT, GCN, XGBoost等），我们采用了 **4-fold 模型集成预测**。即利用交叉验证过程中训练出的 4 个模型分别进行推理，通过结果投票的方式得到最终预测值。这种策略有效提升了模型的泛化能力与预测稳定性。*（注：LLM 没有训练过程，不涉及此训练集成过程）*。
3.  **实验可复现性**：为了保证实验的可复现性，我们统一固定了随机数种子，并在统一的超参数配置下进行了所有对比实验。
4.  **评价指标**：我们主要通过准确率 (Accuracy) 和 F1 分数 (Macro-F1) 来衡量模型在不平衡类别下的表现。

### 4.1 模型性能对比与分析

不同算法在测试集上的表现如下表所示：

| 模型         | XGBoost    | Random Forest | LLM      | BERT     | GCN                                      |
| :----------- | ---------- | :------------ | -------- | -------- | ---------------------------------------- |
| 特征         | 统计学特征 | 统计学特征    | 文本特征 | 文本特征 | **图结构特征**<br>（包含时间+文本+拓扑） |
| 验证集准确率 | 0.8859     | 0.8368        | 0.9118   | 0.9358   | **0.9539**                               |
| 测试集准确率 | 0.8761     | 0.8348        | 0.8879   | 0.9248   | **0.9425**                               |
| 测试集F1分数 | 0.8344     | 0.8756        | 0.8865   | 0.9243   | **0.9419**                               |

**结果分析**：

1.  **图神经网络 (GCN) 表现最佳**：
    GCN 在所有指标上均拔得头筹，F1 分数高达 **0.9419**。这有力地证明了**传播结构**是谣言检测中最具区分度的特征。谣言往往具有独特的传播拓扑（如单点爆发、层级浅但广度大），这是纯文本模型无法完全捕捉的。

2.  **BERT 展现强大的语义理解力**：
    BERT 取得了 **0.9243** 的高 F1 分数，仅次于 GCN。即使没有利用传播图结构，BERT 依然凭借其预训练的深层语义表示和注意力机制，精准捕捉到了文本中煽动性的语气和微妙的情感倾向。这证明了在缺乏结构信息的情况下，NLP 方法依然是强有力的检测手段。

3.  **传统机器学习模型性价比高**：
    XGBoost 和 Random Forest 虽然只使用了统计学特征，但依然取得了 0.83-0.87 的 F1 分数。这说明简单的用户特征（如粉丝数、是否认证）和传播统计量（如转发数）本身就蕴含了大量信息，在计算资源受限的场景下是不错的选择。

### 4.2 LLM 实验结果：从“预测”到“解释”

尽管 LLM 在性能指标表现并非最优，但其核心价值在于可解释性。在实际的谣言审核场景中，给出一个令人信服的理由往往比给出一个冷冰冰的概率更有价值。实验中，我们发现 LLM 能够像人类审核员一样，综合分析博文内容、用户画像以及评论区的舆论风向。下面以测试集中的“宁波妇儿医院跳楼事件”为例，展示 LLM 的推理过程：

| 输入 (Prompt Context - 截取) | 输出 (LLM Reasoning) |
| :--- | :--- |
| **作者信息**: 粉丝22万, 未认证 <br> **源博文**: 宁波妇儿医院一妇女携带一婴儿跳楼，疑因病重及费用昂贵... [蜡烛][泪] <br> **关键评论截图**: <br> 1. [泪] (早期评论多为情绪发泄) <br> ... <br> 30. **这个不是谣言，只不过不是今天罢了。大约9号发生的惨案。** (后期出现的关键辟谣) | `{"label": 1,` <br> `"confidence": 0.85,` <br> `"reason": "缺乏权威来源，时间信息有误，可能为旧闻。"}` |

在上述案例中，早期的评论主要集中在表达同情（[泪]、[蜡烛]），这极易误导基于情感分析的模型将其判定为“真实发生的悲剧”。然而，Gemini 2.5 Flash Lite 敏锐地捕捉到了第 30 条评论中的关键信息——“不是今天”、“大约9号发生的”。模型最终输出的理由是“时间信息有误，可能为旧闻”，这证明了：模型不仅仅看到了“辟谣”二字，而是理解了评论区指出的“时间矛盾”。它没有被前 20 条评论的悲伤情绪带偏，而是基于“事实核查”的逻辑做出了判断。

要进一步提升 LLM 的性能，我们认为可以从以下两点切入：1）使用更强的旗舰级模型（如 Gemini 3.0 Pro），其超长上下文窗口允许我们拼接更多评论，且更强的推理能力有助于提升表现；2）探索将传播图结构转化为文本描述（Graph-to-Text），让 LLM 也能利用结构信息进行判断。


## 五、 总结与展望

通过本次项目，我们构建了一个包含多种主流算法的谣言检测系统。实验结果表明，不同类型的模型各有千秋：
- **传统机器学习模型（RF, XGBoost）**在依赖强人工特征的情况下，依然表现出了惊人的竞争力，且训练效率极高，具有很好的解释性。
- **深度学习模型（BERT）**在文本语义理解上具有绝对优势，能捕捉到微妙的语言风格差异。
- **图神经网络（GCN）**则证明了结构信息在社交网络挖掘中的核心地位，对于复杂的传播模式具有最强的建模能力。
- **大语言模型（LLM）**展示了极强的零样本推理潜力，为未来的辅助审核提供了新的思路。

未来，我们计划进一步探索**图文多模态**（结合图片内容）的检测方法，以及研究如何提升模型在面对全新突发事件时的泛化能力。
