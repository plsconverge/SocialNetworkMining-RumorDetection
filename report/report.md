# 社交网络挖掘项目报告：谣言检测


## 一、 选题介绍

在当今社交媒体高度发达的时代，信息的传播速度呈指数级增长。然而，这也为虚假信息和谣言的扩散提供了温床。谣言的广泛传播不仅会扰乱网络秩序，还可能引发社会恐慌，造成严重的现实后果。因此，如何利用计算机技术自动、高效地检测社交网络中的谣言，成为了一个极具挑战且意义重大的课题。

本小组选择“谣言监测”（Rumor Detection）作为本次项目的课题。我们的核心任务是构建一个二分类模型，根据已知的社交媒体帖子和相关的传播行为（如转发、评论等），将这个信息划分为“谣言”（Rumor）或者“非谣言”（Non-Rumor）。为了直观识别谣言和非谣言在传播中的特征和区别，我们首先进行探索性数据分析（EDA）来可视化数据集的部分特征，并以此指导后续特征工程建模。

方法上，我们根据处理谣言检测问题的常见范式，分别探索了传统特征工程和基于图拓扑结构的建模，也尝试引入大语言模型（LLM）进行无需训练的推理。结果上，我们训练的图神经网络（GCN）模型性能表现优异，在测试集上达到 0.9425 的准确率。此外，我们从 LLM 的推理输出中发现其具备精准捕捉语义细节，给出可靠判据的能力。

本篇报告的后续内容如下组织：第二部分介绍了我们使用的数据集，并展示和分析 EDA 的结果；第三部分从原理上解释了我们使用的三个维度的五个模型；第四部分展示了我们在数据集上做的实验和各个模型性能对比，并结合可视化结果对数据的特征做了解释；第五部分总结了我们的项目并展望可以开展的进一步工作。


## 二、 数据集介绍

本次实验中，我们使用了 **CED (Chinese Rumor Dataset)** 数据集 (<a href="#Song2018">Song et al., 2018</a>)。该数据集包含从微博平台爬取的1538条谣言数据和1849条非谣言数据，为我们的谣言监测任务提供了丰富的特征。数据集中涉及的谣言和非谣言帖子都经过微博社区管理中心认证，确保了数据标签（Label）的准确性与权威性。

CED数据集包含了鲜明的层次结构特征。对每一个样本，它包含了作为根节点的原始信息帖子的特征和传播树中各个子节点的转发行为。对于根节点，数据集包含了信息文本、发布时间和发布用户的特征（包括粉丝数、关注数、是否认证等）。对于转发子节点，数据集包含了转发文本、转发时间和转发的原帖，构成了完整的传播树结构。

数据集的具体大小如下表所示。需要说明的是，虽然谣言和非谣言都存在很小的转发树，但这种极端的数据占比并不多，经过检查，转发数大小小于20个节点的数据仅有7条，说明数据集整体提供了足够大的传播结构特征。

|  数据集   | 数据量 | 转发量 | 平均转发树大小 | 最小转发树大小 | 最大转发树大小 |
| :-------: | :----: | :----: | :------------: | :------------: | :------------: |
|   Rumor   |  1538  | 483617 |      314       |       3        |      954       |
| Non-Rumor |  1849  | 791563 |      428       |       5        |      964       |

### 2.1 数据可视化与探索性分析

我们首先展示部分信息传播图的可视化。为了保证可视化结果的代表性，我们对谣言和非谣言数据集分别选取了三个随机的序号，分别为谣言数据集 [52, 229, 1310], 非谣言数据集 [502, 564, 1519]（报告中序数从1开始计数）。它们的可视化结果完整展示如下：

<table>
  <tr>
    <td align="center">
      <img src="../results/Rumor_Propagation_1.png" style="zoom:48%;"/>
    </td>
    <td align="center">
      <img src="../results/NonRumor_Propagation_1.png" style="zoom:48%;"/>
    </td>
  </tr>
  <tr>
    <td align="center">
      <img src="../results/Rumor_Propagation_2.png" style="zoom:48%;"/>
    </td>
    <td align="center">
      <img src="../results/NonRumor_Propagation_2.png" style="zoom:48%;"/>
    </td>
  </tr>
  <tr>
    <td align="center">
      <img src="../results/Rumor_Propagation_3.png" style="zoom:48%;"/>
    </td>
    <td align="center">
      <img src="../results/NonRumor_Propagation_3.png" style="zoom:48%;"/>
    </td>
  </tr>
</table>
在传播图可视化结果中，我们通过根节点使用红色或者绿色区分谣言与非谣言。对于其他节点，我们区分了带有和不带有转发文本内容的节点。具体而言，带有转发文本的节点显示为蓝色，而转发文本为空的节点显示为灰色。由于直接展示完整传播图时，会出现节点过密导致可视化效果较差的现象，我们将没有孩子节点的一级转发节点每十个合并为一个。合并发生在蓝色节点或者灰色节点内部，所以得到的新节点继承了原节点的颜色，用于反映转发节点的文本特征。

由于我们抽取的传播图在总数据中占比依旧较小，我们从这六张传播图可视化结果中得到的解读不能完整代表所有数据，但可以提供一些简单的洞见，为我们后续的特征工程提供指导。我们可以发现，非谣言的传播树中灰色节点的占比相对较多，且在564号非谣言传播图中，出现了明显的灰色节点集中分布、集中转发的现象。而谣言传播图中，三张图都出现了明显的超长转发链，这是我们在非谣言传播图中没有发现的。我们猜测这可能反映了谣言传播中对真实性或者具体细节的深入讨论，或者对辟谣信息的印证和传播。

为了进一步探索谣言和非谣言数据的异同，我们做了全体数据维度的可视化内容。我们首先绘制了转发行为在一天二十四小时内的分布直方图。如下图所示，可以发现非谣言的转发在晚上23点至凌晨1点之间有一个明显的高峰，而其他时间段的分布大体相同。

<table>
  <tr>
    <td align="center">
      <img src="../results/Rumor_Daily.png" style="zoom:48%;"/>
    </td>
    <td align="center">
      <img src="../results/NonRumor_Daily.png" style="zoom:48%;"/>
    </td>
  </tr>
</table>

接着，我们可视化了每条转发信息相比于前一条转发间隔的时间。从下图的对比中，可以发现非谣言在0-5秒内的聚集转发占比更大，而谣言的转发会更加集中在15-120秒一条的间隔上。

<table>
  <tr>
    <td align="center">
      <img src="../results/Rumor_Interval.png" style="zoom:48%;"/>
    </td>
    <td align="center">
      <img src="../results/NonRumor_Interval.png" style="zoom:48%;"/>
    </td>
  </tr>
</table>

结合上述可视化结果，我们认为，整体上谣言的传播更加具有参与个体的真实性，而非谣言的传播存在深夜聚集转发和短时爆发性传播的现象，更可能存在水军的参与。

我们还对谣言和非谣言传播树的文本信息做了可视化，下面是两类信息的词云图。谣言的传播文本中，存在“吃惊”“怒”“汗”等等表示强烈情感的词语，以及“真的”“怎么”等加强语气的词语，透露出与情感的高相关性。而非谣言的传播文本中，存在“偷笑”“嘻嘻”“喜欢”等等相对比较轻松的词语，虽然依旧有“爱”“泪”等情感表达的词语，但整体情感相关词语较少，而且更加泛化。我们猜测，谣言的传播中，根节点通过夸大事实，引发大众情绪来博取关注，而非谣言的传播中，大家更加偏向聊轻松的、日常的话题，情感波动较小。

<table>
  <tr>
    <td align="center">
      <img src="../results/Rumor_Wordcloud.png" style="zoom:48%;"/>
    </td>
    <td align="center">
      <img src="../results/NonRumor_Wordcloud.png" style="zoom:48%;"/>
    </td>
  </tr>
</table>


## 三、 算法模型

本章节中，我们将分别介绍我们在传统机器学习、深度学习和大语言模型推理三个维度下使用的处理方法。我们希望通过对比利用不同特征维度的模型效果，找到谣言监测任务下最适配的处理方法。

### 1. 传统机器学习建模

在传统机器学习中，我们测试了经典的 Random Forest (随机森林) 和 XGBoost (梯度提升树) 模型。基于数据集的内容和可视化的结果，我们设计了一系列手工特征，以捕捉样本在统计学、图拓扑结构等方面的信息，为分类和解释提供参考。需要说明的是，由于预计到文本特征对谣言的分类效果会有显著提升，我们为了测试其他维度特征的重要性，同时也是为了基于传统机器学习提供一个基线标准，没有在这里引入数据的文本特征。

首先，我们直接包含了数据集提供的部分统计学特征，主要包括：根节点图片数、评论数、转发数、获赞数、发布时间、根节点发布用户是否已认证、是否有个人简介、性别、消息数、粉丝数、好友数。这些特征主要从根节点的帖子和发布用户层面描述了样本。

其次，我们基于传播树的图结构引入了一些简单的特征，主要包括：传播图大小（转发数）、节点最大出度、平均出度、出度的标准差。这些节点从传播树的基本特征和传播行为可能涉及的特征方面描述了样本数据。

最后，我们基于可视化结果设计了如下特征：1）无文本转发的节点比例；2）传播树深度；3）23:00-24:00 发生的转发数、0:00-1:00 发生的转发数；4）间隔15秒内转发的节点数。

### 2. BERT (预训练语言模型)

BERT (Bidirectional Encoder Representations from Transformers) 是深度学习在 NLP 领域的里程碑。为了适配社交媒体谣言检测的多模态特性，我们并没有简单地直接套用原版 BERT，而是设计了一种基于语义增强的混合融合架构。

我们的 BERT 模型实现了一个独特的 **多模态后期融合架构**。社交媒体数据天然包含“非结构化文本”和“结构化数值”两类信息。我们的模型包含两个并行的特征提取流：1）文本流：利用 bert-base-chinese 作为骨干网络，通过 Transformer 编码器提取深层语义特征，取 [CLS] 向量作为整个事件的语义表示。2）数值流：将根节点的粉丝数、点赞数等数值特征标准化后，通过一个多层感知机 (MLP) 映射到高维空间。最终，我们将两路特征在分类层前进行拼接融合。这种设计使得模型既能理解“文本说了什么”（语义维度），又能考量“账号可信度如何”（社会学维度）。

### 3. LLM (Large Language Model - Gemini)

大语言模型（LLM）是当今人工智能中炙手可热的研究领域，具有广阔应用前景。我们在项目中调用 **Gemini 2.5 Flash Lite** API 进行无训练推理，探索通用 LLM 在任务上小样本推理的能力。选择这一模型主要从推理效率和经济效益出发，Flash Lite 版本在保持极高语义理解能力的同时，推理速度极快且成本低廉，这使得大规模、实时处理社交媒体数据成为可能。

我们将谣言检测任务转化为一个“基于证据的推理”问题。与传统模型不同，LLM 不需要繁琐的特征工程，而是直接阅读我们构建的 Prompt。Prompt 的设计采取结构化的方式，包含角色设定的系统指令、待判断内容和回答格式要求，用 LLM 友好的方式精准表述任务和要求。我们要求 LLM 不仅输出分类结果，还要输出推理的置信度和理由。这种 **“可解释性”** 是我们认为 LLM 相比于 BERT 等黑盒模型最大的应用价值所在。

我们给 LLM 提供了几个层面的信息：源博文、发布者关键数值特征和精心挑选的评论。我们采取了 **"Front-K + Back-M"** 策略（保留最早K条和最晚M条评论），这样的设计完美契合了谣言“始于煽动，止于智者”的传播规律。为了进一步提高推理的效率，我们还使用了 asyncio 和 Semaphore 进行异步并发推理，显著提升了大规模数据的检测效率。最后，由于 LLM 的回答存在小概率格式未严格遵循指令的可能，我们并构建了鲁棒的解析器，实现了层次化的解析。



### 4. GCN (图卷积神经网络)

图神经网络（GCN）是我们本次项目的重点，也是针对社交网络数据结构最自然的建模方式，因为谣言的传播本质上就是一个图结构的扩散过程。为了充分利用传播图的拓扑结构与节点内容的深层语义，我们参考 <a href="#Dou2021">Dou et al.(2021)</a> 的项目设计了一种 **“双路特征增强图神经网络” (Dual-Branch GNN)**。其核心思想是在捕捉传播模式的同时，显式地保留源博文的完整语义信息，防止在深层图卷积中发生信息丢失。模型架构如下图所示：

<div align="center">
  <img src="../results/gcn_structure.png" width="80%">
  <br>
  <b>图：双路增强 GCN 模型架构示意图</b>
</div>


我们首先利用预训练的 BERT 模型为传播树中的每一个节点（无论是源帖还是评论）提取了 768 维的语义向量，并拼接了 6 维的时间特征（[年, 月, 日, 时, 分, 秒]）。这意味着图中的每个节点都携带了丰富的语义和时序信息。随后，我们采用 **GraphSAGE (SAGEConv)** 算子进行邻居信息的聚合。GraphSAGE 是一种归纳式学习框架，能有效处理大规模图数据。我们使用**全局最大池化 (Global Max Pooling)** 来得到图的表示，这是因为在谣言检测中，往往某几条关键的“辟谣评论”或“剧烈情感爆发”就是判定谣言的关键证据。

由于源博文所包含的语义信息相当关键，这些信息可能在图卷积的过程中被稀释。因此，模型中采用了一个类似残差连接的结构，直接提取根节点（源博文）的特征向量，通过一个独立的 MLP 映射到高维空间。最终，我们将“图的全局特征”与“根节点的局部特征”进行拼接。这种设计确保了模型在理解宏观传播模式（如水军刷量、爆发式扩散）的同时，始终紧扣微观的源头内容（如博文本身的煽动性）



## 四、实验结果与分析

本章将从量化指标全面、稳健地评估不同模型的性能，并根据机器学习模型提供的重要性排序， 分析不同特征对区分谣言与非谣言信息的帮助。随后，我们将以一个具体的案例来展示和分析 LLM 的可解释性。

**实验设置与评估准则**：
1.  **稳健性评估**：我们采用了 **4 折交叉验证 (4-fold Cross Validation)** 策略。将训练集划分为 4 个子集，轮流作为验证集，以减少因数据划分偏差导致的性能波动，确保评估结果的真实可靠。
2.  **集成推理策略**：在最终的测试集预测中，对于需要训练的模型（BERT, GCN, XGBoost等），我们采用了 **4-fold 模型集成预测**。即利用交叉验证过程中训练出的 4 个模型分别进行推理，通过结果投票的方式得到最终预测值。这种策略有效提升了模型的泛化能力与预测稳定性。*（注：LLM 没有训练过程，不涉及此训练集成过程）*。
3.  **实验可复现性**：为了保证实验的可复现性，我们统一固定了随机数种子，并在统一的超参数配置下进行了所有对比实验。
4.  **评价指标**：我们主要通过准确率 (Accuracy) 和 F1 分数 (Macro-F1) 来衡量模型在不平衡类别下的表现。

### 4.1 模型性能对比与分析

不同算法在测试集上的表现如下表所示：

| 模型         | XGBoost    | Random Forest | LLM      | BERT     | GCN                                      |
| :----------- | ---------- | :------------ | -------- | -------- | ---------------------------------------- |
| 特征         | 统计学特征 | 统计学特征    | 文本特征 | 文本特征 | **图结构特征**<br>（包含时间+文本+拓扑） |
| 验证集准确率 | 0.8859     | 0.8368        | 0.9118   | 0.9358   | **0.9539**                               |
| 测试集准确率 | 0.8761     | 0.8348        | 0.8879   | 0.9248   | **0.9425**                               |
| 测试集F1分数 | 0.8344     | 0.8756        | 0.8865   | 0.9243   | **0.9419**                               |

根据表格，图神经网络在所有指标上都取得了最好的效果。这有力的证明了**传播结构**是谣言检测中最具区分度的特征。从朴素的理解来看，谣言往往被认为具有独特的传播拓扑（如单点爆发、层级浅但广度大），这是纯文本的模型无法完全捕捉的。但对于纯文本的模型，BERT 也能达到 **0.9243** 的 F1 分数，仅次于 GCN。即使没有利用传播图结构，BERT 依然凭借其预训练的深层语义表示和注意力机制，精准捕捉到了文本中煽动性的语气和微妙的情感倾向。这证明了在缺乏结构信息的情况下，NLP 方法依然是强有力的检测手段。尤其是对于**较为早期的谣言检测**，我们往往缺乏较为完整的传播结构，此时 NLP 方法可能能为检测与控制谣言的扩散带来重要的帮助。

### 4.2 手工特征重要性分析

我们基于传统机器学习模型的训练结果，给出了不同特征的重要性排序。由于算法原理的问题，XGBoost 的特征重要性结果中会排除高度线性相关的结果。为了提供对数据特征完整的解释，我们这里将展示 Random Forest 模型的特征重要性排序。我们同时使用了sklearn内置的特征重要性和排序重要性函数，后者通过随机打乱一个固定特征内部的值，测试模型性能相应的下降值。前五重要的特征如下表：

| 特征（内置特征重要性） |  重要性  | 特征（排序重要性） |  重要性  |
| :--------------------: | :------: | :----------------: | :------: |
|          hour          | 0.257270 |        hour        | 0.103540 |
|       followers        | 0.184528 |     followers      | 0.066224 |
|      00:00_repost      | 0.156575 |    00:00_repost    | 0.010177 |
|     std_out_degree     | 0.076227 |   std_out_degree   | 0.005310 |
|     max_out_degree     | 0.061086 |       depth        | 0.004720 |

从表中可以看出，hour, followers 在不同的特征重要性排序算法中都展示了相当的重要性。hour 特征的解释性说明谣言和非谣言在根节点的发布时间上可能存在明显的差异。我们为此对根节点的发布时间做了可视化，结果如下图所示。可以看到，非谣言的根节点发布时间高度集中于晚上23点至凌晨0点这个时间段内，而谣言的根节点发布时间则较为均匀。我们认为这很可能是数据集作者在收集数据时，对数据的时间有一定的偏好，而且仅从非谣言的不合理特征，我们无法对谣言的检测有很大的帮助。这个现象也能一定程度解释非谣言的转发中，在晚上23点至凌晨1点间的节点较多的现象。

<table>
  <tr>
    <td align="center">
      <img src="../results/Rumor_Root.png" style="zoom:48%;"/>
    </td>
    <td align="center">
      <img src="../results/NonRumor_Root.png" style="zoom:48%;"/>
    </td>
  </tr>
</table>
排除掉数据可能存在的不平衡的问题。仅从特征重要性上，我们能看到一些可解释的现象。首先，followers 作为一个重要的特征，提示消息发布者的可信度对它是否是谣言有较为明显的解释作用。其次，节点出度的标准差和最大值作为特征都有较高的重要性。根据我们可视化的传播图，我们推测谣言的传播中，转发和讨论会更加均匀。而非谣言的传播中，由于更可能存在的意见领袖个体，转发和讨论会更加集中，也会带来更大的节点出度。同时，传播树的深度也作为相对重要的特征出现。这印证了我们在可视化中发现的超长传播链的现象。


### 4.3 LLM 实验结果：从“预测”到“解释”

尽管 LLM 在性能指标表现并非最优，但其核心价值在于可解释性。在实际的谣言审核场景中，给出一个令人信服的理由往往比给出一个冷冰冰的概率更有价值。实验中，我们发现 LLM 能够像人类审核员一样，综合分析博文内容、用户画像以及评论区的舆论风向。下面以测试集中的“宁波妇儿医院跳楼事件”为例，展示 LLM 的推理过程：

| 输入 (Prompt Context - 截取) | 输出 (LLM Reasoning) |
| :--- | :--- |
| **作者信息**: 粉丝22万, 未认证 <br> **源博文**: 宁波妇儿医院一妇女携带一婴儿跳楼，疑因病重及费用昂贵... [蜡烛][泪] <br> **关键评论截图**: <br> 1. [泪] (早期评论多为情绪发泄) <br> ... <br> 30. **这个不是谣言，只不过不是今天罢了。大约9号发生的惨案。** (后期出现的关键辟谣) | `{"label": 1,` <br> `"confidence": 0.85,` <br> `"reason": "缺乏权威来源，时间信息有误，可能为旧闻。"}` |

在上述案例中，早期的评论主要集中在表达同情（[泪]、[蜡烛]），这极易误导基于情感分析的模型将其判定为“真实发生的悲剧”。然而，Gemini 2.5 Flash Lite 敏锐地捕捉到了第 30 条评论中的关键信息——“不是今天”、“大约9号发生的”。模型最终输出的理由是“时间信息有误，可能为旧闻”，这证明了：模型不仅仅看到了“辟谣”二字，而是理解了评论区指出的“时间矛盾”。它没有被前 20 条评论的悲伤情绪带偏，而是基于“事实核查”的逻辑做出了判断。

要进一步提升 LLM 的性能，我们认为可以从以下两点切入：1）使用更强的旗舰级模型（如 Gemini 3.0 Pro），其超长上下文窗口允许我们拼接更多评论，且更强的推理能力有助于提升表现；2）探索将传播图结构转化为文本描述（Graph-to-Text），让 LLM 也能利用结构信息进行判断。



## 五、 总结与展望

### 5.1 项目总结：多维视角的融合

本项目的核心价值在于验证了社交媒体谣言检测需要多维视角的协同。实验表明，单一的文本语义（BERT）或统计特征（XGBoost）虽然有效，但都存在盲区。唯有图神经网络（GCN）通过将微观的语义信息与宏观的传播拓扑相结合，才能捕捉到谣言“始于煽动，成于传播”的本质特征。此外，大语言模型（LLM）虽然在绝对精度上略逊一筹，但其提供的逻辑归因能力为解决“算法黑箱”问题提供了全新的范式，证明了“人机协同审核”的可行性。

### 5.2 未来展望：从静态检测到动态防御

基于当前的局限性和数据集中蕴含的丰富信息，我们认为可以从以下几个方向进一步探索：

1.  **动态图时序建模**：
    目前的 GCN 将传播树视为静态图，虽然利用了时间特征，但忽略了节点生成的**动态演化过程**。利用数据集中精确的时间戳信息，引入 **TGN (Temporal Graph Networks)** 或**时序点过程**，捕捉传播过程中的“爆发速率”和“节奏模式”，有望进一步提升对早期谣言的拦截能力。

2.  **异质图网络构建**：
    当前的图结构仅包含“帖子”节点。未来可构建包含“用户”、“话题”、“外链”等多种节点的**异质图**。通过建模“用户-关注-用户”或“水军-共同转发-谣言”的复杂关系网络，可以从群体行为的角度更精准地识别有组织的水军团伙。

3.  **RAG 增强的知识验证**：
    目前的 LLM 推理仅依赖于评论区的内部信息。如果评论区缺乏有效辟谣，模型容易失效。未来应引入**检索增强生成 (RAG)** 技术，赋予 LLM 联网检索官方新闻或查询外部知识库的能力，从而实现基于事实的硬核辟谣，而非仅仅依赖舆论风向。
    
    
    
## 六、参考文献

<a id="Song2018"></a>
**Song, C.**, Tu, C., Yang, C., Liu, Z., & Sun, M. (2018). 
CED: Credible early detection of social media rumors. 
arXiv preprint arXiv:1811.04175. 
https://arxiv.org/abs/1811.04175

<a id="Dou2021"></a>
**Dou, Y.**, Shu, K., Xia, C., Yu, P. S., & Sun, L. (2021). 
User preference-aware fake news detection. 
arXiv preprint arXiv:2104.12259. 
https://arxiv.org/abs/2104.12259

## 七、小组分工

郎健淇：完成了数据清洗工作和可视化工作的主要内容，并负责了传统机器学习部分和GCN模型部分的设计和实现；撰写报告中相应的算法原理和可视化结果解释部分；此外，作为组长统筹安排了此次课题的完整实现

尹鹏程：主要负责 BERT 与 LLM 模块的设计与实现，包括 Prompt 优化及异步推理框架搭建；撰写报告中相应的算法原理部分、实验结果分析及总结展望章节；此外，引入 GitHub Actions 搭建 CI 流水线，保障了项目的代码规范与工程质量。

张子瞭：负责期末项目汇报的ppt制作以及汇报；负责项目报告框架的搭建。